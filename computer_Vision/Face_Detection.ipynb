{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUPQxC_7pLDO"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install tensorflow_datasets opencv-python\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# celebA 데이터셋 로드\n",
        "ds = tfds.load('celeb_a', split='train', shuffle_files=True)\n",
        "\n",
        "# OpenCV의 Haar Cascade 얼굴 검출기 초기화\n",
        "face_cascade = cv2.CascadeClassifier()\n",
        "face_cascade.load(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "def detect_faces(image):\n",
        "    # RGB 이미지를 그레이스케일로 변환\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # 얼굴 검출\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    # 검출된 얼굴에 사각형 그리기\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지 하나를 가져와서 얼굴 검출 수행\n",
        "for example in ds.take(1):  # 데이터셋의 첫 번째 이미지 사용\n",
        "    image = example['image'].numpy()\n",
        "    detected_image = detect_faces(image)\n",
        "\n",
        "    # 이미지 출력\n",
        "    plt.imshow(cv2.cvtColor(detected_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uS2QjQ_LrZ0b"
      },
      "outputs": [],
      "source": [
        "#https://image.dongascience.com/Photo/2020/06/7dc4e8fb10ed0cce7ff5e21521187389.jpg\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# 이미지의 URL을 정의\n",
        "#image_url = 'https://image.dongascience.com/Photo/2020/06/7dc4e8fb10ed0cce7ff5e21521187389.jpg'  # 예시 URL이며, 실제 사용하려는 이미지의 URL로 변경해야 합니다.\n",
        "#image_url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTfGy8L0kyEiHAWqfw_DSRN0XEKxC4IFkGSr_1PIXrbKlmoDyTUESdMIF4VBi0XjslYdJU&usqp=CAU'\n",
        "image_url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQYiTaDqfjqbHyDuXDdMg-mC1PGNZuVPxzQ6A&usqp=CAU'\n",
        "\n",
        "# 이미지 데이터를 가져옴\n",
        "response = requests.get(image_url)\n",
        "\n",
        "# 요청이 성공했는지 확인합\n",
        "if response.status_code == 200:\n",
        "    # 바이트 데이터로 이미지를 열고 저장\n",
        "    image = Image.open(BytesIO(response.content))\n",
        "    image.save('downloaded_image.jpg')\n",
        "    print('Image downloaded successfully.')\n",
        "else:\n",
        "    print('Image could not be retrieved.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9ZgBjJqpOCT"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install tensorflow opencv-python\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# YOLO 가중치와 구성 파일 다운로드\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
        "\n",
        "\n",
        "# YOLO 모델 로드\n",
        "net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
        "\n",
        "# GPU를 사용할 수 있다면, CUDA를 사용하여 YOLO 설정\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "\n",
        "# COCO 데이터셋의 클래스 레이블 로드\n",
        "labels = open('coco.names').read().strip().split('\\n')\n",
        "\n",
        "# 얼굴을 포함하는 클래스 레이블의 인덱스 찾기 (person 클래스)\n",
        "face_label_index = labels.index('person')\n",
        "\n",
        "# 이미지 로드\n",
        "image = cv2.imread('downloaded_image.jpg')  # 여기에 이미지 경로를 넣으세요.\n",
        "(H, W) = image.shape[:2]\n",
        "\n",
        "# YOLO 입력 설정\n",
        "blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "net.setInput(blob)\n",
        "\n",
        "# 객체 검출 수행\n",
        "layer_outputs = net.forward(net.getUnconnectedOutLayersNames())\n",
        "\n",
        "# 검출 결과 시각화\n",
        "for output in layer_outputs:\n",
        "    for detection in output:\n",
        "        scores = detection[5:]\n",
        "        classID = np.argmax(scores)\n",
        "        confidence = scores[classID]\n",
        "        if classID == face_label_index and confidence > 0.5:\n",
        "            # 바운딩 박스 계산\n",
        "            box = detection[0:4] * np.array([W, H, W, H])\n",
        "            (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "            x = int(centerX - (width / 2))\n",
        "            y = int(centerY - (height / 2))\n",
        "\n",
        "            # 이미지에 바운딩 박스와 레이블 추가\n",
        "            cv2.rectangle(image, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
        "            text = \"{}: {:.4f}\".format(labels[classID], confidence)\n",
        "            cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# 최종 이미지를 matplotlib을 사용하여 출력\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTuzXgBPtaep"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install tf_slim\n",
        "!pip install tensorflow-object-detection-api\n",
        "\n",
        "# 모델을 다운로드하기 위한 도구들을 설치\n",
        "!apt-get install -y -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "# object_detection을 위한 repository를 클론\n",
        "!git clone --q https://github.com/tensorflow/models.git\n",
        "\n",
        "# 필요한 패키지 설치\n",
        "!cd models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tV6qu5eD-mc"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install -q tf_slim\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "%cd models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJCuCSkMKL4I"
      },
      "outputs": [],
      "source": [
        "#https://image.dongascience.com/Photo/2020/06/7dc4e8fb10ed0cce7ff5e21521187389.jpg\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# 이미지의 URL을 정의\n",
        "#image_url = 'https://image.dongascience.com/Photo/2020/06/7dc4e8fb10ed0cce7ff5e21521187389.jpg'  # 예시 URL이며, 실제 사용하려는 이미지의 URL로 변경해야 합니다.\n",
        "#image_url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTfGy8L0kyEiHAWqfw_DSRN0XEKxC4IFkGSr_1PIXrbKlmoDyTUESdMIF4VBi0XjslYdJU&usqp=CAU'\n",
        "image_url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQYiTaDqfjqbHyDuXDdMg-mC1PGNZuVPxzQ6A&usqp=CAU'\n",
        "\n",
        "# 이미지 데이터를 가져옴\n",
        "response = requests.get(image_url)\n",
        "\n",
        "# 요청이 성공했는지 확인\n",
        "if response.status_code == 200:\n",
        "    # 바이트 데이터로 이미지를 열고 저장\n",
        "    image = Image.open(BytesIO(response.content))\n",
        "    image.save('downloaded_image.jpg')\n",
        "    print('Image downloaded successfully.')\n",
        "else:\n",
        "    print('Image could not be retrieved.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJpe7U9mJiHn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# 객체 탐지 모델 다운로드\n",
        "model_name = 'faster_rcnn_inception_v2_coco_2018_01_28'\n",
        "model_file = model_name + '.tar.gz'\n",
        "download_base = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "model_dir = tf.keras.utils.get_file(\n",
        "  fname=model_name,\n",
        "  origin=download_base + model_file,\n",
        "  untar=True)\n",
        "model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
        "\n",
        "# 모델 로드\n",
        "detection_model = tf.saved_model.load(str(model_dir))\n",
        "\n",
        "# 레이블 맵 로드\n",
        "PATH_TO_LABELS = 'object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "# 이미지 처리 함수\n",
        "def load_image_into_numpy_array(path):\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "# 추론을 위한 함수\n",
        "def run_inference_for_single_image(model, image):\n",
        "    image = np.asarray(image)\n",
        "    input_tensor = tf.convert_to_tensor(image)\n",
        "    input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "    model_fn = model.signatures['serving_default']\n",
        "    output_dict = model_fn(input_tensor)\n",
        "\n",
        "    num_detections = int(output_dict.pop('num_detections'))\n",
        "    output_dict = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in output_dict.items()}\n",
        "    output_dict['num_detections'] = num_detections\n",
        "\n",
        "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "    if 'detection_masks' in output_dict:\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "                image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                           tf.uint8)\n",
        "        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "# 이미지 로드 및 실행\n",
        "image_path = 'downloaded_image.jpg'  # 이미지 경로\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "output_dict = run_inference_for_single_image(detection_model, image_np)\n",
        "\n",
        "# output_dict 출력\n",
        "print(\"Output Dictionary:\")\n",
        "print(output_dict)\n",
        "\n",
        "# 결과 시각화\n",
        "image = Image.open(image_path)\n",
        "print(image)\n",
        "image_width, image_height = image.size\n",
        "# 화면 해상도를 고려한 figsize 계산 (여기서는 100 dpi로 가정)\n",
        "figsize_width = image_width / 100.0\n",
        "figsize_height = image_height / 100.0\n",
        "\n",
        "plt.figure(figsize=(figsize_width, figsize_height))\n",
        "vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    image_np,\n",
        "    output_dict['detection_boxes'],\n",
        "    output_dict['detection_classes'],\n",
        "    output_dict['detection_scores'],\n",
        "    category_index,\n",
        "    instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "    use_normalized_coordinates=True,\n",
        "    line_thickness=8)\n",
        "\n",
        "plt.imshow(image_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unmThvbPL9Rm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
