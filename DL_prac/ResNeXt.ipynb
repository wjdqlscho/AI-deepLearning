{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using Device:\", device)\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbf2s8x9aDZh",
        "outputId": "f18091dc-d6e1-4309-8870-9157d9e9f220"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpqCksrYZ007",
        "outputId": "3a66b19c-5829-40e6-de39-81a195fd71ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 43.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10 data ready!\n"
          ]
        }
      ],
      "source": [
        "# CIFAR-10 데이터셋 로드\n",
        "# -----------------------\n",
        "transform = transforms.Compose([\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "print('CIFAR-10 data ready!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.2 ResNeXt Bottleneck\n",
        "# -----------------------\n",
        "def conv1x1(in_channels, out_channels, stride=1):\n",
        "  return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "class ResNeXtBottleneck(nn.Module):\n",
        "  expansion = 4\n",
        "  def __init__(self, in_channels, out_channels, cardinality=8, base_width=4, stride=1, downsample=None):\n",
        "    super(ResNeXtBottleneck, self).__init__()\n",
        "    # width calculation\n",
        "    width = int((out_channels // self.expansion) * (base_width / 64.0) * cardinality)\n",
        "    # 1x1 reduce\n",
        "    self.conv1 = nn.Conv2d(in_channels, width, kernel_size=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(width)\n",
        "    # 3x3 group conv\n",
        "    self.conv2 = nn.Conv2d(width, width, kernel_size=3,\n",
        "    stride=stride, padding=1,\n",
        "    groups=cardinality, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(width)\n",
        "    # 1x1 expand\n",
        "    self.conv3 = nn.Conv2d(width, out_channels, kernel_size=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.downsample = downsample\n",
        "    self.stride = stride\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn3(out)\n",
        "\n",
        "    if self.downsample is not None:\n",
        "      identity = self.downsample(x)\n",
        "\n",
        "    out += identity\n",
        "    out = self.relu(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "wINvwmE4aMhT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.3 Simple ResNeXt for CIFAR-10\n",
        "# -----------------------\n",
        "class ResNeXtCIFAR(nn.Module):\n",
        "  def __init__(self, layers=[2,2,2], cardinality=8, base_width=4, num_classes=10):\n",
        "    super(ResNeXtCIFAR, self).__init__()\n",
        "    self.in_channels = 64\n",
        "    # initial conv\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    # stages\n",
        "    self.layer1 = self._make_layer(64, layers[0], cardinality, base_width, stride=1)\n",
        "    self.layer2 = self._make_layer(128, layers[1], cardinality, base_width, stride=2)\n",
        "    self.layer3 = self._make_layer(256, layers[2], cardinality, base_width, stride=2)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(256*ResNeXtBottleneck.expansion, num_classes)\n",
        "\n",
        "  def _make_layer(self, out_channels, blocks, cardinality, base_width, stride=1):\n",
        "    downsample = None\n",
        "    if stride != 1 or self.in_channels != out_channels*ResNeXtBottleneck.expansion:\n",
        "      downsample = nn.Sequential(\n",
        "          conv1x1(self.in_channels, out_channels*ResNeXtBottleneck.expansion, stride),\n",
        "          nn.BatchNorm2d(out_channels*ResNeXtBottleneck.expansion)\n",
        "          )\n",
        "\n",
        "    layers = []\n",
        "    layers.append(\n",
        "        ResNeXtBottleneck(\n",
        "          self.in_channels,\n",
        "          out_channels*ResNeXtBottleneck.expansion,\n",
        "          cardinality=cardinality,\n",
        "          base_width=base_width,\n",
        "          stride=stride,\n",
        "          downsample=downsample\n",
        "        )\n",
        "      )\n",
        "    self.in_channels = out_channels*ResNeXtBottleneck.expansion\n",
        "\n",
        "    for _ in range(1, blocks):\n",
        "      layers.append(\n",
        "        ResNeXtBottleneck(\n",
        "        self.in_channels,\n",
        "        out_channels*ResNeXtBottleneck.expansion,\n",
        "        cardinality=cardinality,\n",
        "        base_width=base_width\n",
        "        )\n",
        "    )\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "def resnext_cifar_demo():\n",
        "   return ResNeXtCIFAR(layers=[2,2,2], cardinality=8, base_width=4, num_classes=10)\n",
        "\n",
        "model = resnext_cifar_demo().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGc9bwLKb1ns",
        "outputId": "f51ca4c0-6683-44e0-bc42-a45687ab829a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNeXtCIFAR(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): ResNeXtBottleneck(\n",
            "      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResNeXtBottleneck(\n",
            "      (conv1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): ResNeXtBottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResNeXtBottleneck(\n",
            "      (conv1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): ResNeXtBottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResNeXtBottleneck(\n",
            "      (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}