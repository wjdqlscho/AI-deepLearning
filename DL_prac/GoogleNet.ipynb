{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0kaHZYUcFQC",
        "outputId": "7c272c89-3554-453a-d4a2-70f46d016cb5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋으로 CIFAR-10 사용\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "    ])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "print('CIFAR-10 data ready!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzsNbWGvbk6P",
        "outputId": "0af99048-d859-4514-dc69-149fb05623ea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10 data ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인셉션 블록\n",
        "\n",
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(self, in_channels, c1, c3r, c3, c5r, c5, pool_proj):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "        # Branch1: 1x1 Conv\n",
        "        self.branch1 = nn.Conv2d(in_channels, c1, kernel_size=1, bias=False)\n",
        "        # Branch2: 1x1 -> 3x3\n",
        "        self.branch2_1 = nn.Conv2d(in_channels, c3r, kernel_size=1, bias=False)\n",
        "        self.branch2_2 = nn.Conv2d(c3r, c3, kernel_size=3, padding=1, bias=False)\n",
        "        # Branch3: 1x1 -> 5x5\n",
        "        self.branch3_1 = nn.Conv2d(in_channels, c5r, kernel_size=1, bias=False)\n",
        "        self.branch3_2 = nn.Conv2d(c5r, c5, kernel_size=5, padding=2, bias=False)\n",
        "        # Branch4: Pool -> 1x1\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        self.branch4 = nn.Conv2d(in_channels, pool_proj, kernel_size=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(c1 + c3 + c5 + pool_proj)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b1 = self.branch1(x)\n",
        "\n",
        "        b2 = self.branch2_1(x)\n",
        "        b2 = F.relu(b2, inplace=True)\n",
        "        b2 = self.branch2_2(b2)\n",
        "\n",
        "        b3 = self.branch3_1(x)\n",
        "        b3 = F.relu(b3, inplace=True)\n",
        "        b3 = self.branch3_2(b3)\n",
        "\n",
        "        b4 = self.pool(x)\n",
        "        b4 = self.branch4(b4)\n",
        "\n",
        "        out = torch.cat([b1, b2, b3, b4], dim=1)\n",
        "        out = self.bn(out)\n",
        "\n",
        "        return F.relu(out, inplace=True)"
      ],
      "metadata": {
        "id": "24BZdXgRa907"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# 4.3 Simple Inception Net for CIFAR-10\n",
        "# -----------------------\n",
        "class SimpleInceptionNet(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(SimpleInceptionNet, self).__init__()\n",
        "    # initial conv\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    # Inception blocks\n",
        "    self.inc1 = InceptionBlock(in_channels=64, c1=16, c3r=16, c3=24, c5r=16, c5=24, pool_proj=16)\n",
        "    self.inc2 = InceptionBlock(in_channels=16+24+24+16, c1=32, c3r=32, c3=48, c5r=16, c5=24, pool_proj=24)\n",
        "    # total out channels=128\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.inc3 = InceptionBlock(in_channels=128, c1=32, c3r=32, c3=48, c5r=16, c5=24, pool_proj=24)\n",
        "    self.bn2 = nn.BatchNorm2d(128)\n",
        "    self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = F.relu(x, inplace=True)\n",
        "    x = self.inc1(x)\n",
        "    x = self.inc2(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.inc3(x)\n",
        "    x = self.bn2(x)\n",
        "    x = F.relu(x, inplace=True)\n",
        "    x = F.adaptive_avg_pool2d(x, (1,1))\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "model = SimpleInceptionNet().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNAnP674b37K",
        "outputId": "577b6e7c-b731-44a2-ab4b-6ccfbaa23ceb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleInceptionNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (inc1): InceptionBlock(\n",
            "    (branch1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (branch2_1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (branch2_2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (branch3_1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (branch3_2): Conv2d(16, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (pool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (branch4): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (inc2): InceptionBlock(\n",
            "    (branch1): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (branch2_1): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (branch2_2): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (branch3_1): Conv2d(80, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (branch3_2): Conv2d(16, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (pool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (branch4): Conv2d(80, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (inc3): InceptionBlock(\n",
            "    (branch1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (branch2_1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (branch2_2): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (branch3_1): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (branch3_2): Conv2d(16, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (pool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (branch4): Conv2d(128, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for images, labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "\n",
        "avg_loss = running_loss / len(train_loader)\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    out = model(images)\n",
        "    _, predicted = torch.max(out, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "acc = 100.0 * correct / total\n",
        "print(f\"Epoch {epoch}, Loss: {avg_loss:.4f}, Test Acc: {acc:.2f}%\")"
      ],
      "metadata": {
        "id": "mjuurs3jcD9W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}