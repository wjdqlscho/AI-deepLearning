{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2. Device 설정\n",
        "- 일반적으로 인공신경망의 학습은 (가능하다면) GPU를 사용하는 것이 바람직함\n",
        "    - Colab Runtime 설정 변경\n",
        "- GPU를 사용하여 학습을 진행하도록 명시적으로 작성 필요\n",
        "- 연산 유형에 따라 GPU에서 수행이 불가능한 경우도 존재하는데, 그럴 경우도 마찬가지로 명시적으로 어떤 프로세서에서 연산을 수행해야하는지 코드로 작성해야함\n",
        "\n",
        "```\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = NeuralNetwork().to(device)\n",
        "```\n"
      ],
      "metadata": {
        "id": "e0H3duTdrqi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 신경망 생성\n",
        "\n",
        "- **torch.nn 패키지**는 신경망 생성 및 학습 시 설정해야하는 다양한 기능을 제공\n",
        "\n",
        "```\n",
        "import torch.nn as nn\n",
        "```\n",
        "- 신경망을 **nn.Module**을 상속받아 정의\n",
        "    - __ __init__ __(): 신경망에서 사용할 layer를 초기화하는 부분\n",
        "    - __forward()__: feed foward 연산 수행 시, 각 layer의 입출력이 어떻게 연결되는지를 지정\n",
        "\n",
        "```\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.input_layer    = nn.Linear(4, 16)\n",
        "        self.hidden_layer1  = nn.Linear(16, 32)\n",
        "        self.output_layer   = nn.Linear(32, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out =  self.relu(self.input_layer(x))\n",
        "        out =  self.relu(self.hidden_layer1(out))\n",
        "        out =  self.output_layer(out)\n",
        "        return out\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "IvGB8XKLrndB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Model compile\n",
        "\n",
        "- 학습 시 필요한 정보들(loss function, optimizer)을 선언\n",
        "- 일반적으로 loss와 optimizer는 아래와 같이 변수로 선언하고, 변수를 train/test 시 참고할 수 있도록 매개변수로 지정해줌\n",
        "\n",
        "```\n",
        "learning_rate = 0.01\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "```\n"
      ],
      "metadata": {
        "id": "kdaqKz_DrveR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Train\n",
        "- **신경망의 학습과정**을 별도의 함수로 구성하는 것이 일반적\n",
        "    - feed forward -> loss -> error back propagation -> (log) -> (반복)\n",
        "\n",
        "```\n",
        "def train_loop(train_loader, model, loss_fn, optimizer):\n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        optimizer.zero_grad() 옵티마이저 초기화 하는 거임\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "```"
      ],
      "metadata": {
        "id": "6QL46lI-ryBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Test\n",
        "\n",
        "- 학습과정과 비슷하나 error back propagate하는 부분이 없음\n",
        "    - feed forward -> loss ->  (log) -> (반복)\n",
        "\n",
        "```\n",
        "def test_loop(test_loader, model, loss_fn):\n",
        "    size = len(test_loader.dataset)\n",
        "    num_batches = len(test_loader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:8f}\\n\")\n"
      ],
      "metadata": {
        "id": "366tXVkAr93J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Iteration\n",
        "- 신경망 학습은 여러 epochs을 반복해서 수행하면서 모델을 구성하는 최적의 파라미터를 찾음\n",
        "- 지정한 epochs 수만큼 **학습**과정과 **평가**과정을 반복하면서, 모델의 성능(loss, accuracy 등)을 체크함\n",
        "\n",
        "```\n",
        "epochs = 10\n",
        "for i in range(epochs) :\n",
        "    print(f\"Epoch {i+1} \\n------------------------\")\n",
        "    train_loop(train_dataloader, model, loss, optimizer)\n",
        "    test_loop(test_dataloader, model, loss)\n",
        "print(\"Done!\")\n",
        "```"
      ],
      "metadata": {
        "id": "kFQKm4PesSfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "# 코드로 형식 지정됨\n",
        "```\n",
        "\n",
        "#### [Step1] Load libraries & Datasets"
      ],
      "metadata": {
        "id": "D6Wgb2BJtHsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import  TensorDataset, DataLoader\n",
        "\n",
        "# 데이터 불러오기\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['label'] = iris.target\n",
        "\n",
        "# 데이터분할\n",
        "y = df['label']\n",
        "X = df.drop(['label'], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "qEz5KQnCsv0Z"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [Step2] Create DataLoader\n"
      ],
      "metadata": {
        "id": "fztPvCKFtOy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.int64)\n",
        "y_test = torch.tensor(y_test, dtype=torch.int64)\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "LCzLLCRctQ2v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [Step3] Set Network Structure"
      ],
      "metadata": {
        "id": "MhmaMSaUtTIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.input_layer    = nn.Linear(4, 16)\n",
        "        self.hidden_layer1  = nn.Linear(16, 32)\n",
        "        self.output_layer   = nn.Linear(32, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        out =  self.relu(self.input_layer(x))\n",
        "        out =  self.relu(self.hidden_layer1(out))\n",
        "        out =  self.output_layer(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "4yA_6ldotVRQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [Step4] Create Model instance"
      ],
      "metadata": {
        "id": "zRJ7NO03thVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'device = {device}')\n",
        "\n",
        "model = NeuralNetwork().to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xp2G30at3Bq",
        "outputId": "79eb4f27-e88f-4174-bd2d-3fac52ff129a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device = cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [Step5] Model compile"
      ],
      "metadata": {
        "id": "0xT56WSVtsuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일\n",
        "learning_rate = 0.001\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "torTUBV-t-co"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [Step6] Set train loop"
      ],
      "metadata": {
        "id": "psPfsDFKtuz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(train_loader, model, loss_fn, optimizer):\n",
        "    size = len(train_loader.dataset)\n",
        "\n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "\n",
        "        # 손실 계산\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss, current = loss.item(), batch * len(X)\n",
        "        print(f'loss: {loss:>7f}  [{current:>5d}]/{size:5d}')\n"
      ],
      "metadata": {
        "id": "u3VFGyShuA-4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [Step7] Set test loop"
      ],
      "metadata": {
        "id": "oKh70HcztxmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(test_loader, model, loss_fn):\n",
        "    size = len(test_loader.dataset)\n",
        "    num_batches = len(test_loader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:8f}\\n\")"
      ],
      "metadata": {
        "id": "UQ4VPQbzuKyA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [Step8] Run model"
      ],
      "metadata": {
        "id": "yWTH09h1t0YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 실행\n",
        "epochs = 100\n",
        "\n",
        "for i in range(epochs) :\n",
        "    print(f\"Epoch {i+1} \\n------------------------\")\n",
        "    train_loop(train_dataloader, model, loss, optimizer)\n",
        "    test_loop(test_dataloader, model, loss)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcJOST0luStQ",
        "outputId": "3926756f-6ebc-4206-b0cc-e6dc8da534cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            "------------------------\n",
            "loss: 0.652478  [    0]/  112\n",
            "loss: 0.596696  [   10]/  112\n",
            "loss: 0.640371  [   20]/  112\n",
            "loss: 0.695265  [   30]/  112\n",
            "loss: 0.694335  [   40]/  112\n",
            "loss: 0.682260  [   50]/  112\n",
            "loss: 0.570858  [   60]/  112\n",
            "loss: 0.599914  [   70]/  112\n",
            "loss: 0.568515  [   80]/  112\n",
            "loss: 0.604858  [   90]/  112\n",
            "loss: 0.554377  [  100]/  112\n",
            "loss: 0.492677  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 73.7%, Avg loss: 0.621627\n",
            "\n",
            "Epoch 2 \n",
            "------------------------\n",
            "loss: 0.679215  [    0]/  112\n",
            "loss: 0.621484  [   10]/  112\n",
            "loss: 0.602441  [   20]/  112\n",
            "loss: 0.451242  [   30]/  112\n",
            "loss: 0.558290  [   40]/  112\n",
            "loss: 0.728410  [   50]/  112\n",
            "loss: 0.596651  [   60]/  112\n",
            "loss: 0.577393  [   70]/  112\n",
            "loss: 0.555414  [   80]/  112\n",
            "loss: 0.537045  [   90]/  112\n",
            "loss: 0.488472  [  100]/  112\n",
            "loss: 0.595725  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 71.1%, Avg loss: 0.578464\n",
            "\n",
            "Epoch 3 \n",
            "------------------------\n",
            "loss: 0.554283  [    0]/  112\n",
            "loss: 0.519121  [   10]/  112\n",
            "loss: 0.496006  [   20]/  112\n",
            "loss: 0.681974  [   30]/  112\n",
            "loss: 0.537144  [   40]/  112\n",
            "loss: 0.486708  [   50]/  112\n",
            "loss: 0.447016  [   60]/  112\n",
            "loss: 0.605278  [   70]/  112\n",
            "loss: 0.609174  [   80]/  112\n",
            "loss: 0.635608  [   90]/  112\n",
            "loss: 0.546874  [  100]/  112\n",
            "loss: 0.259105  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 76.3%, Avg loss: 0.559184\n",
            "\n",
            "Epoch 4 \n",
            "------------------------\n",
            "loss: 0.509171  [    0]/  112\n",
            "loss: 0.470280  [   10]/  112\n",
            "loss: 0.639755  [   20]/  112\n",
            "loss: 0.460454  [   30]/  112\n",
            "loss: 0.580724  [   40]/  112\n",
            "loss: 0.519300  [   50]/  112\n",
            "loss: 0.430106  [   60]/  112\n",
            "loss: 0.554903  [   70]/  112\n",
            "loss: 0.584797  [   80]/  112\n",
            "loss: 0.528106  [   90]/  112\n",
            "loss: 0.398969  [  100]/  112\n",
            "loss: 0.809089  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 81.6%, Avg loss: 0.529258\n",
            "\n",
            "Epoch 5 \n",
            "------------------------\n",
            "loss: 0.435897  [    0]/  112\n",
            "loss: 0.463498  [   10]/  112\n",
            "loss: 0.538846  [   20]/  112\n",
            "loss: 0.558870  [   30]/  112\n",
            "loss: 0.408563  [   40]/  112\n",
            "loss: 0.506534  [   50]/  112\n",
            "loss: 0.583048  [   60]/  112\n",
            "loss: 0.530866  [   70]/  112\n",
            "loss: 0.476287  [   80]/  112\n",
            "loss: 0.495176  [   90]/  112\n",
            "loss: 0.481347  [  100]/  112\n",
            "loss: 0.601436  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.512216\n",
            "\n",
            "Epoch 6 \n",
            "------------------------\n",
            "loss: 0.586925  [    0]/  112\n",
            "loss: 0.501328  [   10]/  112\n",
            "loss: 0.431777  [   20]/  112\n",
            "loss: 0.370555  [   30]/  112\n",
            "loss: 0.349934  [   40]/  112\n",
            "loss: 0.403033  [   50]/  112\n",
            "loss: 0.408885  [   60]/  112\n",
            "loss: 0.595612  [   70]/  112\n",
            "loss: 0.552675  [   80]/  112\n",
            "loss: 0.536411  [   90]/  112\n",
            "loss: 0.507339  [  100]/  112\n",
            "loss: 0.469248  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 81.6%, Avg loss: 0.487887\n",
            "\n",
            "Epoch 7 \n",
            "------------------------\n",
            "loss: 0.464379  [    0]/  112\n",
            "loss: 0.547941  [   10]/  112\n",
            "loss: 0.431824  [   20]/  112\n",
            "loss: 0.380283  [   30]/  112\n",
            "loss: 0.486812  [   40]/  112\n",
            "loss: 0.455489  [   50]/  112\n",
            "loss: 0.465157  [   60]/  112\n",
            "loss: 0.464607  [   70]/  112\n",
            "loss: 0.371327  [   80]/  112\n",
            "loss: 0.475801  [   90]/  112\n",
            "loss: 0.449692  [  100]/  112\n",
            "loss: 0.411089  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.468246\n",
            "\n",
            "Epoch 8 \n",
            "------------------------\n",
            "loss: 0.487527  [    0]/  112\n",
            "loss: 0.459116  [   10]/  112\n",
            "loss: 0.317438  [   20]/  112\n",
            "loss: 0.390506  [   30]/  112\n",
            "loss: 0.463356  [   40]/  112\n",
            "loss: 0.521960  [   50]/  112\n",
            "loss: 0.480813  [   60]/  112\n",
            "loss: 0.469121  [   70]/  112\n",
            "loss: 0.413629  [   80]/  112\n",
            "loss: 0.348909  [   90]/  112\n",
            "loss: 0.483345  [  100]/  112\n",
            "loss: 0.153674  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 92.1%, Avg loss: 0.446213\n",
            "\n",
            "Epoch 9 \n",
            "------------------------\n",
            "loss: 0.372661  [    0]/  112\n",
            "loss: 0.363688  [   10]/  112\n",
            "loss: 0.323451  [   20]/  112\n",
            "loss: 0.543241  [   30]/  112\n",
            "loss: 0.427817  [   40]/  112\n",
            "loss: 0.434193  [   50]/  112\n",
            "loss: 0.491703  [   60]/  112\n",
            "loss: 0.313557  [   70]/  112\n",
            "loss: 0.520475  [   80]/  112\n",
            "loss: 0.291903  [   90]/  112\n",
            "loss: 0.496823  [  100]/  112\n",
            "loss: 0.318999  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.436871\n",
            "\n",
            "Epoch 10 \n",
            "------------------------\n",
            "loss: 0.468470  [    0]/  112\n",
            "loss: 0.454613  [   10]/  112\n",
            "loss: 0.265711  [   20]/  112\n",
            "loss: 0.374852  [   30]/  112\n",
            "loss: 0.467488  [   40]/  112\n",
            "loss: 0.303624  [   50]/  112\n",
            "loss: 0.427626  [   60]/  112\n",
            "loss: 0.385436  [   70]/  112\n",
            "loss: 0.590295  [   80]/  112\n",
            "loss: 0.218125  [   90]/  112\n",
            "loss: 0.434968  [  100]/  112\n",
            "loss: 0.379904  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.417404\n",
            "\n",
            "Epoch 11 \n",
            "------------------------\n",
            "loss: 0.328392  [    0]/  112\n",
            "loss: 0.385188  [   10]/  112\n",
            "loss: 0.396780  [   20]/  112\n",
            "loss: 0.417548  [   30]/  112\n",
            "loss: 0.516914  [   40]/  112\n",
            "loss: 0.350246  [   50]/  112\n",
            "loss: 0.401362  [   60]/  112\n",
            "loss: 0.496751  [   70]/  112\n",
            "loss: 0.329898  [   80]/  112\n",
            "loss: 0.393085  [   90]/  112\n",
            "loss: 0.362704  [  100]/  112\n",
            "loss: 0.339024  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.395553\n",
            "\n",
            "Epoch 12 \n",
            "------------------------\n",
            "loss: 0.450157  [    0]/  112\n",
            "loss: 0.379023  [   10]/  112\n",
            "loss: 0.392306  [   20]/  112\n",
            "loss: 0.301970  [   30]/  112\n",
            "loss: 0.454234  [   40]/  112\n",
            "loss: 0.324183  [   50]/  112\n",
            "loss: 0.316488  [   60]/  112\n",
            "loss: 0.296948  [   70]/  112\n",
            "loss: 0.329322  [   80]/  112\n",
            "loss: 0.394440  [   90]/  112\n",
            "loss: 0.429498  [  100]/  112\n",
            "loss: 0.359542  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 84.2%, Avg loss: 0.386822\n",
            "\n",
            "Epoch 13 \n",
            "------------------------\n",
            "loss: 0.395767  [    0]/  112\n",
            "loss: 0.328665  [   10]/  112\n",
            "loss: 0.396138  [   20]/  112\n",
            "loss: 0.361914  [   30]/  112\n",
            "loss: 0.285573  [   40]/  112\n",
            "loss: 0.363520  [   50]/  112\n",
            "loss: 0.302109  [   60]/  112\n",
            "loss: 0.315894  [   70]/  112\n",
            "loss: 0.373424  [   80]/  112\n",
            "loss: 0.518538  [   90]/  112\n",
            "loss: 0.373830  [  100]/  112\n",
            "loss: 0.107877  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.369672\n",
            "\n",
            "Epoch 14 \n",
            "------------------------\n",
            "loss: 0.315225  [    0]/  112\n",
            "loss: 0.298821  [   10]/  112\n",
            "loss: 0.488374  [   20]/  112\n",
            "loss: 0.418266  [   30]/  112\n",
            "loss: 0.233320  [   40]/  112\n",
            "loss: 0.479949  [   50]/  112\n",
            "loss: 0.360340  [   60]/  112\n",
            "loss: 0.329648  [   70]/  112\n",
            "loss: 0.260955  [   80]/  112\n",
            "loss: 0.289859  [   90]/  112\n",
            "loss: 0.348474  [  100]/  112\n",
            "loss: 0.293774  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.360866\n",
            "\n",
            "Epoch 15 \n",
            "------------------------\n",
            "loss: 0.364085  [    0]/  112\n",
            "loss: 0.309956  [   10]/  112\n",
            "loss: 0.394570  [   20]/  112\n",
            "loss: 0.429738  [   30]/  112\n",
            "loss: 0.334259  [   40]/  112\n",
            "loss: 0.291553  [   50]/  112\n",
            "loss: 0.280586  [   60]/  112\n",
            "loss: 0.314356  [   70]/  112\n",
            "loss: 0.472436  [   80]/  112\n",
            "loss: 0.196988  [   90]/  112\n",
            "loss: 0.302104  [  100]/  112\n",
            "loss: 0.082879  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.353273\n",
            "\n",
            "Epoch 16 \n",
            "------------------------\n",
            "loss: 0.490859  [    0]/  112\n",
            "loss: 0.304371  [   10]/  112\n",
            "loss: 0.429822  [   20]/  112\n",
            "loss: 0.303419  [   30]/  112\n",
            "loss: 0.280054  [   40]/  112\n",
            "loss: 0.243440  [   50]/  112\n",
            "loss: 0.299010  [   60]/  112\n",
            "loss: 0.284705  [   70]/  112\n",
            "loss: 0.385130  [   80]/  112\n",
            "loss: 0.258371  [   90]/  112\n",
            "loss: 0.308001  [  100]/  112\n",
            "loss: 0.343691  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.337242\n",
            "\n",
            "Epoch 17 \n",
            "------------------------\n",
            "loss: 0.205476  [    0]/  112\n",
            "loss: 0.357256  [   10]/  112\n",
            "loss: 0.304722  [   20]/  112\n",
            "loss: 0.413161  [   30]/  112\n",
            "loss: 0.273115  [   40]/  112\n",
            "loss: 0.269217  [   50]/  112\n",
            "loss: 0.267117  [   60]/  112\n",
            "loss: 0.310147  [   70]/  112\n",
            "loss: 0.245975  [   80]/  112\n",
            "loss: 0.345514  [   90]/  112\n",
            "loss: 0.377172  [  100]/  112\n",
            "loss: 0.418645  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.326532\n",
            "\n",
            "Epoch 18 \n",
            "------------------------\n",
            "loss: 0.330033  [    0]/  112\n",
            "loss: 0.354777  [   10]/  112\n",
            "loss: 0.262419  [   20]/  112\n",
            "loss: 0.313223  [   30]/  112\n",
            "loss: 0.367777  [   40]/  112\n",
            "loss: 0.284237  [   50]/  112\n",
            "loss: 0.331632  [   60]/  112\n",
            "loss: 0.367350  [   70]/  112\n",
            "loss: 0.325555  [   80]/  112\n",
            "loss: 0.195089  [   90]/  112\n",
            "loss: 0.167227  [  100]/  112\n",
            "loss: 0.089454  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.313017\n",
            "\n",
            "Epoch 19 \n",
            "------------------------\n",
            "loss: 0.254717  [    0]/  112\n",
            "loss: 0.295116  [   10]/  112\n",
            "loss: 0.358563  [   20]/  112\n",
            "loss: 0.361704  [   30]/  112\n",
            "loss: 0.256403  [   40]/  112\n",
            "loss: 0.148332  [   50]/  112\n",
            "loss: 0.337117  [   60]/  112\n",
            "loss: 0.277756  [   70]/  112\n",
            "loss: 0.243580  [   80]/  112\n",
            "loss: 0.381274  [   90]/  112\n",
            "loss: 0.178969  [  100]/  112\n",
            "loss: 0.494846  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.306118\n",
            "\n",
            "Epoch 20 \n",
            "------------------------\n",
            "loss: 0.323055  [    0]/  112\n",
            "loss: 0.101607  [   10]/  112\n",
            "loss: 0.306504  [   20]/  112\n",
            "loss: 0.303975  [   30]/  112\n",
            "loss: 0.213507  [   40]/  112\n",
            "loss: 0.367063  [   50]/  112\n",
            "loss: 0.309207  [   60]/  112\n",
            "loss: 0.244558  [   70]/  112\n",
            "loss: 0.243210  [   80]/  112\n",
            "loss: 0.332460  [   90]/  112\n",
            "loss: 0.338505  [  100]/  112\n",
            "loss: 0.089826  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.295422\n",
            "\n",
            "Epoch 21 \n",
            "------------------------\n",
            "loss: 0.285700  [    0]/  112\n",
            "loss: 0.209579  [   10]/  112\n",
            "loss: 0.262689  [   20]/  112\n",
            "loss: 0.248945  [   30]/  112\n",
            "loss: 0.279592  [   40]/  112\n",
            "loss: 0.349136  [   50]/  112\n",
            "loss: 0.244144  [   60]/  112\n",
            "loss: 0.226465  [   70]/  112\n",
            "loss: 0.263167  [   80]/  112\n",
            "loss: 0.373463  [   90]/  112\n",
            "loss: 0.165873  [  100]/  112\n",
            "loss: 0.292384  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.284541\n",
            "\n",
            "Epoch 22 \n",
            "------------------------\n",
            "loss: 0.099238  [    0]/  112\n",
            "loss: 0.330761  [   10]/  112\n",
            "loss: 0.302182  [   20]/  112\n",
            "loss: 0.260170  [   30]/  112\n",
            "loss: 0.227152  [   40]/  112\n",
            "loss: 0.292622  [   50]/  112\n",
            "loss: 0.273229  [   60]/  112\n",
            "loss: 0.244179  [   70]/  112\n",
            "loss: 0.291219  [   80]/  112\n",
            "loss: 0.284556  [   90]/  112\n",
            "loss: 0.280304  [  100]/  112\n",
            "loss: 0.131644  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.280098\n",
            "\n",
            "Epoch 23 \n",
            "------------------------\n",
            "loss: 0.175867  [    0]/  112\n",
            "loss: 0.299312  [   10]/  112\n",
            "loss: 0.220798  [   20]/  112\n",
            "loss: 0.308029  [   30]/  112\n",
            "loss: 0.187601  [   40]/  112\n",
            "loss: 0.192930  [   50]/  112\n",
            "loss: 0.219321  [   60]/  112\n",
            "loss: 0.292539  [   70]/  112\n",
            "loss: 0.278840  [   80]/  112\n",
            "loss: 0.283971  [   90]/  112\n",
            "loss: 0.257404  [  100]/  112\n",
            "loss: 0.296081  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 97.4%, Avg loss: 0.267080\n",
            "\n",
            "Epoch 24 \n",
            "------------------------\n",
            "loss: 0.346184  [    0]/  112\n",
            "loss: 0.246704  [   10]/  112\n",
            "loss: 0.251230  [   20]/  112\n",
            "loss: 0.241927  [   30]/  112\n",
            "loss: 0.205532  [   40]/  112\n",
            "loss: 0.098281  [   50]/  112\n",
            "loss: 0.228996  [   60]/  112\n",
            "loss: 0.295415  [   70]/  112\n",
            "loss: 0.222603  [   80]/  112\n",
            "loss: 0.213710  [   90]/  112\n",
            "loss: 0.373113  [  100]/  112\n",
            "loss: 0.086493  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.262363\n",
            "\n",
            "Epoch 25 \n",
            "------------------------\n",
            "loss: 0.173443  [    0]/  112\n",
            "loss: 0.247419  [   10]/  112\n",
            "loss: 0.334381  [   20]/  112\n",
            "loss: 0.190258  [   30]/  112\n",
            "loss: 0.223873  [   40]/  112\n",
            "loss: 0.305150  [   50]/  112\n",
            "loss: 0.138566  [   60]/  112\n",
            "loss: 0.260509  [   70]/  112\n",
            "loss: 0.281631  [   80]/  112\n",
            "loss: 0.173586  [   90]/  112\n",
            "loss: 0.219413  [  100]/  112\n",
            "loss: 0.083283  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.251696\n",
            "\n",
            "Epoch 26 \n",
            "------------------------\n",
            "loss: 0.339612  [    0]/  112\n",
            "loss: 0.171319  [   10]/  112\n",
            "loss: 0.128390  [   20]/  112\n",
            "loss: 0.212688  [   30]/  112\n",
            "loss: 0.193897  [   40]/  112\n",
            "loss: 0.240638  [   50]/  112\n",
            "loss: 0.187617  [   60]/  112\n",
            "loss: 0.305671  [   70]/  112\n",
            "loss: 0.265311  [   80]/  112\n",
            "loss: 0.160825  [   90]/  112\n",
            "loss: 0.215286  [  100]/  112\n",
            "loss: 0.421073  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.242543\n",
            "\n",
            "Epoch 27 \n",
            "------------------------\n",
            "loss: 0.171123  [    0]/  112\n",
            "loss: 0.202756  [   10]/  112\n",
            "loss: 0.200681  [   20]/  112\n",
            "loss: 0.244326  [   30]/  112\n",
            "loss: 0.270580  [   40]/  112\n",
            "loss: 0.255266  [   50]/  112\n",
            "loss: 0.242523  [   60]/  112\n",
            "loss: 0.262650  [   70]/  112\n",
            "loss: 0.283023  [   80]/  112\n",
            "loss: 0.174921  [   90]/  112\n",
            "loss: 0.168918  [  100]/  112\n",
            "loss: 0.075106  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.234388\n",
            "\n",
            "Epoch 28 \n",
            "------------------------\n",
            "loss: 0.214154  [    0]/  112\n",
            "loss: 0.374709  [   10]/  112\n",
            "loss: 0.108747  [   20]/  112\n",
            "loss: 0.235489  [   30]/  112\n",
            "loss: 0.194346  [   40]/  112\n",
            "loss: 0.232197  [   50]/  112\n",
            "loss: 0.212892  [   60]/  112\n",
            "loss: 0.220710  [   70]/  112\n",
            "loss: 0.260679  [   80]/  112\n",
            "loss: 0.166179  [   90]/  112\n",
            "loss: 0.103661  [  100]/  112\n",
            "loss: 0.154320  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.227936\n",
            "\n",
            "Epoch 29 \n",
            "------------------------\n",
            "loss: 0.279621  [    0]/  112\n",
            "loss: 0.107496  [   10]/  112\n",
            "loss: 0.390441  [   20]/  112\n",
            "loss: 0.138924  [   30]/  112\n",
            "loss: 0.195122  [   40]/  112\n",
            "loss: 0.145773  [   50]/  112\n",
            "loss: 0.202391  [   60]/  112\n",
            "loss: 0.140887  [   70]/  112\n",
            "loss: 0.185387  [   80]/  112\n",
            "loss: 0.215939  [   90]/  112\n",
            "loss: 0.225605  [  100]/  112\n",
            "loss: 0.029625  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.218429\n",
            "\n",
            "Epoch 30 \n",
            "------------------------\n",
            "loss: 0.170801  [    0]/  112\n",
            "loss: 0.177398  [   10]/  112\n",
            "loss: 0.212350  [   20]/  112\n",
            "loss: 0.125317  [   30]/  112\n",
            "loss: 0.260276  [   40]/  112\n",
            "loss: 0.185161  [   50]/  112\n",
            "loss: 0.188398  [   60]/  112\n",
            "loss: 0.195789  [   70]/  112\n",
            "loss: 0.199414  [   80]/  112\n",
            "loss: 0.157439  [   90]/  112\n",
            "loss: 0.282187  [  100]/  112\n",
            "loss: 0.169442  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.214298\n",
            "\n",
            "Epoch 31 \n",
            "------------------------\n",
            "loss: 0.217318  [    0]/  112\n",
            "loss: 0.117541  [   10]/  112\n",
            "loss: 0.160834  [   20]/  112\n",
            "loss: 0.121409  [   30]/  112\n",
            "loss: 0.239804  [   40]/  112\n",
            "loss: 0.271471  [   50]/  112\n",
            "loss: 0.111924  [   60]/  112\n",
            "loss: 0.253768  [   70]/  112\n",
            "loss: 0.187217  [   80]/  112\n",
            "loss: 0.156568  [   90]/  112\n",
            "loss: 0.137697  [  100]/  112\n",
            "loss: 0.781102  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.205656\n",
            "\n",
            "Epoch 32 \n",
            "------------------------\n",
            "loss: 0.104443  [    0]/  112\n",
            "loss: 0.260971  [   10]/  112\n",
            "loss: 0.108935  [   20]/  112\n",
            "loss: 0.247532  [   30]/  112\n",
            "loss: 0.403401  [   40]/  112\n",
            "loss: 0.327525  [   50]/  112\n",
            "loss: 0.180881  [   60]/  112\n",
            "loss: 0.249391  [   70]/  112\n",
            "loss: 0.281077  [   80]/  112\n",
            "loss: 0.197418  [   90]/  112\n",
            "loss: 0.099213  [  100]/  112\n",
            "loss: 0.412790  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.201527\n",
            "\n",
            "Epoch 33 \n",
            "------------------------\n",
            "loss: 0.122648  [    0]/  112\n",
            "loss: 0.251950  [   10]/  112\n",
            "loss: 0.152753  [   20]/  112\n",
            "loss: 0.257293  [   30]/  112\n",
            "loss: 0.272895  [   40]/  112\n",
            "loss: 0.135776  [   50]/  112\n",
            "loss: 0.315819  [   60]/  112\n",
            "loss: 0.347387  [   70]/  112\n",
            "loss: 0.117292  [   80]/  112\n",
            "loss: 0.138864  [   90]/  112\n",
            "loss: 0.212333  [  100]/  112\n",
            "loss: 0.048776  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 92.1%, Avg loss: 0.215012\n",
            "\n",
            "Epoch 34 \n",
            "------------------------\n",
            "loss: 0.353629  [    0]/  112\n",
            "loss: 0.187929  [   10]/  112\n",
            "loss: 0.149719  [   20]/  112\n",
            "loss: 0.201333  [   30]/  112\n",
            "loss: 0.121425  [   40]/  112\n",
            "loss: 0.174565  [   50]/  112\n",
            "loss: 0.120340  [   60]/  112\n",
            "loss: 0.141558  [   70]/  112\n",
            "loss: 0.151670  [   80]/  112\n",
            "loss: 0.107674  [   90]/  112\n",
            "loss: 0.272132  [  100]/  112\n",
            "loss: 0.209766  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.189290\n",
            "\n",
            "Epoch 35 \n",
            "------------------------\n",
            "loss: 0.106534  [    0]/  112\n",
            "loss: 0.156917  [   10]/  112\n",
            "loss: 0.283109  [   20]/  112\n",
            "loss: 0.064341  [   30]/  112\n",
            "loss: 0.141550  [   40]/  112\n",
            "loss: 0.249290  [   50]/  112\n",
            "loss: 0.165403  [   60]/  112\n",
            "loss: 0.128023  [   70]/  112\n",
            "loss: 0.272850  [   80]/  112\n",
            "loss: 0.116149  [   90]/  112\n",
            "loss: 0.152851  [  100]/  112\n",
            "loss: 0.233779  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.191137\n",
            "\n",
            "Epoch 36 \n",
            "------------------------\n",
            "loss: 0.180380  [    0]/  112\n",
            "loss: 0.110987  [   10]/  112\n",
            "loss: 0.129851  [   20]/  112\n",
            "loss: 0.171732  [   30]/  112\n",
            "loss: 0.109035  [   40]/  112\n",
            "loss: 0.195138  [   50]/  112\n",
            "loss: 0.186378  [   60]/  112\n",
            "loss: 0.295928  [   70]/  112\n",
            "loss: 0.159255  [   80]/  112\n",
            "loss: 0.139301  [   90]/  112\n",
            "loss: 0.160478  [  100]/  112\n",
            "loss: 0.329894  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.182463\n",
            "\n",
            "Epoch 37 \n",
            "------------------------\n",
            "loss: 0.286022  [    0]/  112\n",
            "loss: 0.163079  [   10]/  112\n",
            "loss: 0.120669  [   20]/  112\n",
            "loss: 0.227026  [   30]/  112\n",
            "loss: 0.095413  [   40]/  112\n",
            "loss: 0.120042  [   50]/  112\n",
            "loss: 0.131514  [   60]/  112\n",
            "loss: 0.104298  [   70]/  112\n",
            "loss: 0.184486  [   80]/  112\n",
            "loss: 0.287772  [   90]/  112\n",
            "loss: 0.055124  [  100]/  112\n",
            "loss: 0.109481  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.182323\n",
            "\n",
            "Epoch 38 \n",
            "------------------------\n",
            "loss: 0.143197  [    0]/  112\n",
            "loss: 0.169544  [   10]/  112\n",
            "loss: 0.121114  [   20]/  112\n",
            "loss: 0.188783  [   30]/  112\n",
            "loss: 0.119609  [   40]/  112\n",
            "loss: 0.256763  [   50]/  112\n",
            "loss: 0.122388  [   60]/  112\n",
            "loss: 0.040141  [   70]/  112\n",
            "loss: 0.116439  [   80]/  112\n",
            "loss: 0.235464  [   90]/  112\n",
            "loss: 0.181577  [  100]/  112\n",
            "loss: 0.440665  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.171545\n",
            "\n",
            "Epoch 39 \n",
            "------------------------\n",
            "loss: 0.251612  [    0]/  112\n",
            "loss: 0.147523  [   10]/  112\n",
            "loss: 0.109347  [   20]/  112\n",
            "loss: 0.219910  [   30]/  112\n",
            "loss: 0.171140  [   40]/  112\n",
            "loss: 0.273271  [   50]/  112\n",
            "loss: 0.161681  [   60]/  112\n",
            "loss: 0.216467  [   70]/  112\n",
            "loss: 0.188052  [   80]/  112\n",
            "loss: 0.132078  [   90]/  112\n",
            "loss: 0.073828  [  100]/  112\n",
            "loss: 0.057700  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.167541\n",
            "\n",
            "Epoch 40 \n",
            "------------------------\n",
            "loss: 0.207982  [    0]/  112\n",
            "loss: 0.146902  [   10]/  112\n",
            "loss: 0.078356  [   20]/  112\n",
            "loss: 0.215602  [   30]/  112\n",
            "loss: 0.127017  [   40]/  112\n",
            "loss: 0.151429  [   50]/  112\n",
            "loss: 0.200734  [   60]/  112\n",
            "loss: 0.140252  [   70]/  112\n",
            "loss: 0.069471  [   80]/  112\n",
            "loss: 0.163600  [   90]/  112\n",
            "loss: 0.204409  [  100]/  112\n",
            "loss: 0.223112  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.168446\n",
            "\n",
            "Epoch 41 \n",
            "------------------------\n",
            "loss: 0.258253  [    0]/  112\n",
            "loss: 0.149149  [   10]/  112\n",
            "loss: 0.101352  [   20]/  112\n",
            "loss: 0.128818  [   30]/  112\n",
            "loss: 0.272426  [   40]/  112\n",
            "loss: 0.108137  [   50]/  112\n",
            "loss: 0.162086  [   60]/  112\n",
            "loss: 0.103304  [   70]/  112\n",
            "loss: 0.152317  [   80]/  112\n",
            "loss: 0.150350  [   90]/  112\n",
            "loss: 0.199149  [  100]/  112\n",
            "loss: 0.096350  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.166505\n",
            "\n",
            "Epoch 42 \n",
            "------------------------\n",
            "loss: 0.150643  [    0]/  112\n",
            "loss: 0.106209  [   10]/  112\n",
            "loss: 0.191739  [   20]/  112\n",
            "loss: 0.079465  [   30]/  112\n",
            "loss: 0.119061  [   40]/  112\n",
            "loss: 0.331920  [   50]/  112\n",
            "loss: 0.088464  [   60]/  112\n",
            "loss: 0.091350  [   70]/  112\n",
            "loss: 0.107039  [   80]/  112\n",
            "loss: 0.179848  [   90]/  112\n",
            "loss: 0.150836  [  100]/  112\n",
            "loss: 0.166291  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.156451\n",
            "\n",
            "Epoch 43 \n",
            "------------------------\n",
            "loss: 0.061950  [    0]/  112\n",
            "loss: 0.092615  [   10]/  112\n",
            "loss: 0.224535  [   20]/  112\n",
            "loss: 0.236435  [   30]/  112\n",
            "loss: 0.090015  [   40]/  112\n",
            "loss: 0.161955  [   50]/  112\n",
            "loss: 0.141930  [   60]/  112\n",
            "loss: 0.056029  [   70]/  112\n",
            "loss: 0.197850  [   80]/  112\n",
            "loss: 0.158606  [   90]/  112\n",
            "loss: 0.092003  [  100]/  112\n",
            "loss: 0.314515  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.154784\n",
            "\n",
            "Epoch 44 \n",
            "------------------------\n",
            "loss: 0.143202  [    0]/  112\n",
            "loss: 0.313401  [   10]/  112\n",
            "loss: 0.081011  [   20]/  112\n",
            "loss: 0.070305  [   30]/  112\n",
            "loss: 0.152233  [   40]/  112\n",
            "loss: 0.076884  [   50]/  112\n",
            "loss: 0.111060  [   60]/  112\n",
            "loss: 0.130883  [   70]/  112\n",
            "loss: 0.072646  [   80]/  112\n",
            "loss: 0.150575  [   90]/  112\n",
            "loss: 0.196590  [  100]/  112\n",
            "loss: 0.280828  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.150972\n",
            "\n",
            "Epoch 45 \n",
            "------------------------\n",
            "loss: 0.101685  [    0]/  112\n",
            "loss: 0.130780  [   10]/  112\n",
            "loss: 0.103850  [   20]/  112\n",
            "loss: 0.134710  [   30]/  112\n",
            "loss: 0.302780  [   40]/  112\n",
            "loss: 0.220878  [   50]/  112\n",
            "loss: 0.088394  [   60]/  112\n",
            "loss: 0.092334  [   70]/  112\n",
            "loss: 0.086945  [   80]/  112\n",
            "loss: 0.067376  [   90]/  112\n",
            "loss: 0.190325  [  100]/  112\n",
            "loss: 0.225812  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 97.4%, Avg loss: 0.150739\n",
            "\n",
            "Epoch 46 \n",
            "------------------------\n",
            "loss: 0.061251  [    0]/  112\n",
            "loss: 0.118712  [   10]/  112\n",
            "loss: 0.063961  [   20]/  112\n",
            "loss: 0.140106  [   30]/  112\n",
            "loss: 0.232484  [   40]/  112\n",
            "loss: 0.073162  [   50]/  112\n",
            "loss: 0.100275  [   60]/  112\n",
            "loss: 0.083677  [   70]/  112\n",
            "loss: 0.321635  [   80]/  112\n",
            "loss: 0.167983  [   90]/  112\n",
            "loss: 0.164805  [  100]/  112\n",
            "loss: 0.178612  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 97.4%, Avg loss: 0.148581\n",
            "\n",
            "Epoch 47 \n",
            "------------------------\n",
            "loss: 0.090560  [    0]/  112\n",
            "loss: 0.140462  [   10]/  112\n",
            "loss: 0.093191  [   20]/  112\n",
            "loss: 0.215281  [   30]/  112\n",
            "loss: 0.131268  [   40]/  112\n",
            "loss: 0.105861  [   50]/  112\n",
            "loss: 0.182384  [   60]/  112\n",
            "loss: 0.080971  [   70]/  112\n",
            "loss: 0.227046  [   80]/  112\n",
            "loss: 0.082529  [   90]/  112\n",
            "loss: 0.146814  [  100]/  112\n",
            "loss: 0.077507  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.140524\n",
            "\n",
            "Epoch 48 \n",
            "------------------------\n",
            "loss: 0.137599  [    0]/  112\n",
            "loss: 0.210897  [   10]/  112\n",
            "loss: 0.070222  [   20]/  112\n",
            "loss: 0.038801  [   30]/  112\n",
            "loss: 0.072436  [   40]/  112\n",
            "loss: 0.187012  [   50]/  112\n",
            "loss: 0.119246  [   60]/  112\n",
            "loss: 0.117657  [   70]/  112\n",
            "loss: 0.180247  [   80]/  112\n",
            "loss: 0.080899  [   90]/  112\n",
            "loss: 0.150373  [  100]/  112\n",
            "loss: 0.305323  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.137731\n",
            "\n",
            "Epoch 49 \n",
            "------------------------\n",
            "loss: 0.116350  [    0]/  112\n",
            "loss: 0.199972  [   10]/  112\n",
            "loss: 0.194378  [   20]/  112\n",
            "loss: 0.127785  [   30]/  112\n",
            "loss: 0.192645  [   40]/  112\n",
            "loss: 0.172499  [   50]/  112\n",
            "loss: 0.107734  [   60]/  112\n",
            "loss: 0.076037  [   70]/  112\n",
            "loss: 0.036883  [   80]/  112\n",
            "loss: 0.147866  [   90]/  112\n",
            "loss: 0.085271  [  100]/  112\n",
            "loss: 0.049378  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.133385\n",
            "\n",
            "Epoch 50 \n",
            "------------------------\n",
            "loss: 0.092754  [    0]/  112\n",
            "loss: 0.039112  [   10]/  112\n",
            "loss: 0.081914  [   20]/  112\n",
            "loss: 0.115251  [   30]/  112\n",
            "loss: 0.203687  [   40]/  112\n",
            "loss: 0.042123  [   50]/  112\n",
            "loss: 0.174376  [   60]/  112\n",
            "loss: 0.071171  [   70]/  112\n",
            "loss: 0.188472  [   80]/  112\n",
            "loss: 0.145569  [   90]/  112\n",
            "loss: 0.154080  [  100]/  112\n",
            "loss: 0.173764  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.136441\n",
            "\n",
            "Epoch 51 \n",
            "------------------------\n",
            "loss: 0.121704  [    0]/  112\n",
            "loss: 0.129027  [   10]/  112\n",
            "loss: 0.115225  [   20]/  112\n",
            "loss: 0.127526  [   30]/  112\n",
            "loss: 0.055826  [   40]/  112\n",
            "loss: 0.082077  [   50]/  112\n",
            "loss: 0.098707  [   60]/  112\n",
            "loss: 0.054130  [   70]/  112\n",
            "loss: 0.126979  [   80]/  112\n",
            "loss: 0.160054  [   90]/  112\n",
            "loss: 0.083458  [  100]/  112\n",
            "loss: 0.909932  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.133900\n",
            "\n",
            "Epoch 52 \n",
            "------------------------\n",
            "loss: 0.092558  [    0]/  112\n",
            "loss: 0.055871  [   10]/  112\n",
            "loss: 0.036574  [   20]/  112\n",
            "loss: 0.207380  [   30]/  112\n",
            "loss: 0.305513  [   40]/  112\n",
            "loss: 0.124234  [   50]/  112\n",
            "loss: 0.077606  [   60]/  112\n",
            "loss: 0.099843  [   70]/  112\n",
            "loss: 0.143065  [   80]/  112\n",
            "loss: 0.140786  [   90]/  112\n",
            "loss: 0.109454  [  100]/  112\n",
            "loss: 0.109085  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.125876\n",
            "\n",
            "Epoch 53 \n",
            "------------------------\n",
            "loss: 0.075729  [    0]/  112\n",
            "loss: 0.162957  [   10]/  112\n",
            "loss: 0.055034  [   20]/  112\n",
            "loss: 0.017008  [   30]/  112\n",
            "loss: 0.158340  [   40]/  112\n",
            "loss: 0.244107  [   50]/  112\n",
            "loss: 0.180697  [   60]/  112\n",
            "loss: 0.089234  [   70]/  112\n",
            "loss: 0.170240  [   80]/  112\n",
            "loss: 0.066742  [   90]/  112\n",
            "loss: 0.073656  [  100]/  112\n",
            "loss: 0.003882  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.121819\n",
            "\n",
            "Epoch 54 \n",
            "------------------------\n",
            "loss: 0.118181  [    0]/  112\n",
            "loss: 0.043555  [   10]/  112\n",
            "loss: 0.122529  [   20]/  112\n",
            "loss: 0.048878  [   30]/  112\n",
            "loss: 0.055687  [   40]/  112\n",
            "loss: 0.092937  [   50]/  112\n",
            "loss: 0.259142  [   60]/  112\n",
            "loss: 0.129870  [   70]/  112\n",
            "loss: 0.088057  [   80]/  112\n",
            "loss: 0.232732  [   90]/  112\n",
            "loss: 0.079749  [  100]/  112\n",
            "loss: 0.012173  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.120621\n",
            "\n",
            "Epoch 55 \n",
            "------------------------\n",
            "loss: 0.049107  [    0]/  112\n",
            "loss: 0.242818  [   10]/  112\n",
            "loss: 0.107428  [   20]/  112\n",
            "loss: 0.179733  [   30]/  112\n",
            "loss: 0.080542  [   40]/  112\n",
            "loss: 0.027274  [   50]/  112\n",
            "loss: 0.165275  [   60]/  112\n",
            "loss: 0.057851  [   70]/  112\n",
            "loss: 0.108797  [   80]/  112\n",
            "loss: 0.091198  [   90]/  112\n",
            "loss: 0.136053  [  100]/  112\n",
            "loss: 0.035687  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.119428\n",
            "\n",
            "Epoch 56 \n",
            "------------------------\n",
            "loss: 0.082980  [    0]/  112\n",
            "loss: 0.090071  [   10]/  112\n",
            "loss: 0.033339  [   20]/  112\n",
            "loss: 0.182297  [   30]/  112\n",
            "loss: 0.116009  [   40]/  112\n",
            "loss: 0.108945  [   50]/  112\n",
            "loss: 0.126570  [   60]/  112\n",
            "loss: 0.064330  [   70]/  112\n",
            "loss: 0.164136  [   80]/  112\n",
            "loss: 0.078337  [   90]/  112\n",
            "loss: 0.115433  [  100]/  112\n",
            "loss: 0.381081  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.122788\n",
            "\n",
            "Epoch 57 \n",
            "------------------------\n",
            "loss: 0.139106  [    0]/  112\n",
            "loss: 0.089543  [   10]/  112\n",
            "loss: 0.106408  [   20]/  112\n",
            "loss: 0.127993  [   30]/  112\n",
            "loss: 0.040994  [   40]/  112\n",
            "loss: 0.133785  [   50]/  112\n",
            "loss: 0.047965  [   60]/  112\n",
            "loss: 0.144058  [   70]/  112\n",
            "loss: 0.104501  [   80]/  112\n",
            "loss: 0.184671  [   90]/  112\n",
            "loss: 0.119349  [  100]/  112\n",
            "loss: 0.081574  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.116921\n",
            "\n",
            "Epoch 58 \n",
            "------------------------\n",
            "loss: 0.084691  [    0]/  112\n",
            "loss: 0.064105  [   10]/  112\n",
            "loss: 0.240060  [   20]/  112\n",
            "loss: 0.054854  [   30]/  112\n",
            "loss: 0.109963  [   40]/  112\n",
            "loss: 0.117012  [   50]/  112\n",
            "loss: 0.146966  [   60]/  112\n",
            "loss: 0.092145  [   70]/  112\n",
            "loss: 0.034756  [   80]/  112\n",
            "loss: 0.174467  [   90]/  112\n",
            "loss: 0.047615  [  100]/  112\n",
            "loss: 0.118627  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.118651\n",
            "\n",
            "Epoch 59 \n",
            "------------------------\n",
            "loss: 0.112225  [    0]/  112\n",
            "loss: 0.069111  [   10]/  112\n",
            "loss: 0.259369  [   20]/  112\n",
            "loss: 0.050161  [   30]/  112\n",
            "loss: 0.043128  [   40]/  112\n",
            "loss: 0.154044  [   50]/  112\n",
            "loss: 0.035615  [   60]/  112\n",
            "loss: 0.059361  [   70]/  112\n",
            "loss: 0.102718  [   80]/  112\n",
            "loss: 0.185758  [   90]/  112\n",
            "loss: 0.148927  [  100]/  112\n",
            "loss: 0.016039  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.111397\n",
            "\n",
            "Epoch 60 \n",
            "------------------------\n",
            "loss: 0.155351  [    0]/  112\n",
            "loss: 0.083897  [   10]/  112\n",
            "loss: 0.081861  [   20]/  112\n",
            "loss: 0.043845  [   30]/  112\n",
            "loss: 0.138209  [   40]/  112\n",
            "loss: 0.087762  [   50]/  112\n",
            "loss: 0.115048  [   60]/  112\n",
            "loss: 0.194381  [   70]/  112\n",
            "loss: 0.055851  [   80]/  112\n",
            "loss: 0.065053  [   90]/  112\n",
            "loss: 0.117418  [  100]/  112\n",
            "loss: 1.008527  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.107626\n",
            "\n",
            "Epoch 61 \n",
            "------------------------\n",
            "loss: 0.036783  [    0]/  112\n",
            "loss: 0.152764  [   10]/  112\n",
            "loss: 0.158366  [   20]/  112\n",
            "loss: 0.114262  [   30]/  112\n",
            "loss: 0.159956  [   40]/  112\n",
            "loss: 0.244941  [   50]/  112\n",
            "loss: 0.061801  [   60]/  112\n",
            "loss: 0.078977  [   70]/  112\n",
            "loss: 0.116542  [   80]/  112\n",
            "loss: 0.143167  [   90]/  112\n",
            "loss: 0.176290  [  100]/  112\n",
            "loss: 0.433110  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.115881\n",
            "\n",
            "Epoch 62 \n",
            "------------------------\n",
            "loss: 0.080143  [    0]/  112\n",
            "loss: 0.046504  [   10]/  112\n",
            "loss: 0.016647  [   20]/  112\n",
            "loss: 0.168991  [   30]/  112\n",
            "loss: 0.082519  [   40]/  112\n",
            "loss: 0.035449  [   50]/  112\n",
            "loss: 0.143372  [   60]/  112\n",
            "loss: 0.069448  [   70]/  112\n",
            "loss: 0.126219  [   80]/  112\n",
            "loss: 0.407720  [   90]/  112\n",
            "loss: 0.188675  [  100]/  112\n",
            "loss: 0.580980  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.126785\n",
            "\n",
            "Epoch 63 \n",
            "------------------------\n",
            "loss: 0.085062  [    0]/  112\n",
            "loss: 0.051072  [   10]/  112\n",
            "loss: 0.099480  [   20]/  112\n",
            "loss: 0.067908  [   30]/  112\n",
            "loss: 0.136729  [   40]/  112\n",
            "loss: 0.112969  [   50]/  112\n",
            "loss: 0.110120  [   60]/  112\n",
            "loss: 0.100192  [   70]/  112\n",
            "loss: 0.033710  [   80]/  112\n",
            "loss: 0.237588  [   90]/  112\n",
            "loss: 0.056592  [  100]/  112\n",
            "loss: 0.022740  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 94.7%, Avg loss: 0.122883\n",
            "\n",
            "Epoch 64 \n",
            "------------------------\n",
            "loss: 0.042120  [    0]/  112\n",
            "loss: 0.126984  [   10]/  112\n",
            "loss: 0.140087  [   20]/  112\n",
            "loss: 0.344095  [   30]/  112\n",
            "loss: 0.047306  [   40]/  112\n",
            "loss: 0.043833  [   50]/  112\n",
            "loss: 0.119173  [   60]/  112\n",
            "loss: 0.048089  [   70]/  112\n",
            "loss: 0.223610  [   80]/  112\n",
            "loss: 0.049074  [   90]/  112\n",
            "loss: 0.053954  [  100]/  112\n",
            "loss: 0.020875  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.108099\n",
            "\n",
            "Epoch 65 \n",
            "------------------------\n",
            "loss: 0.161443  [    0]/  112\n",
            "loss: 0.038192  [   10]/  112\n",
            "loss: 0.091777  [   20]/  112\n",
            "loss: 0.136901  [   30]/  112\n",
            "loss: 0.296370  [   40]/  112\n",
            "loss: 0.075213  [   50]/  112\n",
            "loss: 0.041844  [   60]/  112\n",
            "loss: 0.038415  [   70]/  112\n",
            "loss: 0.113655  [   80]/  112\n",
            "loss: 0.091230  [   90]/  112\n",
            "loss: 0.068875  [  100]/  112\n",
            "loss: 0.002159  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.104367\n",
            "\n",
            "Epoch 66 \n",
            "------------------------\n",
            "loss: 0.022680  [    0]/  112\n",
            "loss: 0.122902  [   10]/  112\n",
            "loss: 0.039140  [   20]/  112\n",
            "loss: 0.223422  [   30]/  112\n",
            "loss: 0.016779  [   40]/  112\n",
            "loss: 0.123830  [   50]/  112\n",
            "loss: 0.070650  [   60]/  112\n",
            "loss: 0.129032  [   70]/  112\n",
            "loss: 0.070172  [   80]/  112\n",
            "loss: 0.127579  [   90]/  112\n",
            "loss: 0.132617  [  100]/  112\n",
            "loss: 0.015333  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.107322\n",
            "\n",
            "Epoch 67 \n",
            "------------------------\n",
            "loss: 0.055796  [    0]/  112\n",
            "loss: 0.107765  [   10]/  112\n",
            "loss: 0.198010  [   20]/  112\n",
            "loss: 0.087674  [   30]/  112\n",
            "loss: 0.081708  [   40]/  112\n",
            "loss: 0.079075  [   50]/  112\n",
            "loss: 0.107265  [   60]/  112\n",
            "loss: 0.091146  [   70]/  112\n",
            "loss: 0.095390  [   80]/  112\n",
            "loss: 0.041642  [   90]/  112\n",
            "loss: 0.129211  [  100]/  112\n",
            "loss: 0.073083  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.100977\n",
            "\n",
            "Epoch 68 \n",
            "------------------------\n",
            "loss: 0.031476  [    0]/  112\n",
            "loss: 0.084302  [   10]/  112\n",
            "loss: 0.059161  [   20]/  112\n",
            "loss: 0.056745  [   30]/  112\n",
            "loss: 0.056686  [   40]/  112\n",
            "loss: 0.255068  [   50]/  112\n",
            "loss: 0.078228  [   60]/  112\n",
            "loss: 0.096570  [   70]/  112\n",
            "loss: 0.090216  [   80]/  112\n",
            "loss: 0.211033  [   90]/  112\n",
            "loss: 0.052910  [  100]/  112\n",
            "loss: 0.002517  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.104068\n",
            "\n",
            "Epoch 69 \n",
            "------------------------\n",
            "loss: 0.098771  [    0]/  112\n",
            "loss: 0.107220  [   10]/  112\n",
            "loss: 0.138155  [   20]/  112\n",
            "loss: 0.256564  [   30]/  112\n",
            "loss: 0.054516  [   40]/  112\n",
            "loss: 0.028684  [   50]/  112\n",
            "loss: 0.032365  [   60]/  112\n",
            "loss: 0.151894  [   70]/  112\n",
            "loss: 0.119140  [   80]/  112\n",
            "loss: 0.091614  [   90]/  112\n",
            "loss: 0.032220  [  100]/  112\n",
            "loss: 0.037821  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.097752\n",
            "\n",
            "Epoch 70 \n",
            "------------------------\n",
            "loss: 0.114234  [    0]/  112\n",
            "loss: 0.015414  [   10]/  112\n",
            "loss: 0.041260  [   20]/  112\n",
            "loss: 0.054066  [   30]/  112\n",
            "loss: 0.049758  [   40]/  112\n",
            "loss: 0.038279  [   50]/  112\n",
            "loss: 0.075919  [   60]/  112\n",
            "loss: 0.331724  [   70]/  112\n",
            "loss: 0.100772  [   80]/  112\n",
            "loss: 0.190551  [   90]/  112\n",
            "loss: 0.197933  [  100]/  112\n",
            "loss: 0.046792  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.098090\n",
            "\n",
            "Epoch 71 \n",
            "------------------------\n",
            "loss: 0.087325  [    0]/  112\n",
            "loss: 0.023788  [   10]/  112\n",
            "loss: 0.030303  [   20]/  112\n",
            "loss: 0.128716  [   30]/  112\n",
            "loss: 0.196429  [   40]/  112\n",
            "loss: 0.155339  [   50]/  112\n",
            "loss: 0.113137  [   60]/  112\n",
            "loss: 0.034831  [   70]/  112\n",
            "loss: 0.067197  [   80]/  112\n",
            "loss: 0.140779  [   90]/  112\n",
            "loss: 0.057147  [  100]/  112\n",
            "loss: 0.001285  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.098037\n",
            "\n",
            "Epoch 72 \n",
            "------------------------\n",
            "loss: 0.065400  [    0]/  112\n",
            "loss: 0.099387  [   10]/  112\n",
            "loss: 0.037511  [   20]/  112\n",
            "loss: 0.087505  [   30]/  112\n",
            "loss: 0.023729  [   40]/  112\n",
            "loss: 0.070555  [   50]/  112\n",
            "loss: 0.089177  [   60]/  112\n",
            "loss: 0.061635  [   70]/  112\n",
            "loss: 0.143437  [   80]/  112\n",
            "loss: 0.017802  [   90]/  112\n",
            "loss: 0.168340  [  100]/  112\n",
            "loss: 0.877487  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.100332\n",
            "\n",
            "Epoch 73 \n",
            "------------------------\n",
            "loss: 0.053515  [    0]/  112\n",
            "loss: 0.066336  [   10]/  112\n",
            "loss: 0.284684  [   20]/  112\n",
            "loss: 0.120977  [   30]/  112\n",
            "loss: 0.314973  [   40]/  112\n",
            "loss: 0.039328  [   50]/  112\n",
            "loss: 0.054845  [   60]/  112\n",
            "loss: 0.015161  [   70]/  112\n",
            "loss: 0.099582  [   80]/  112\n",
            "loss: 0.029133  [   90]/  112\n",
            "loss: 0.027176  [  100]/  112\n",
            "loss: 0.022027  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.094542\n",
            "\n",
            "Epoch 74 \n",
            "------------------------\n",
            "loss: 0.045763  [    0]/  112\n",
            "loss: 0.112456  [   10]/  112\n",
            "loss: 0.079205  [   20]/  112\n",
            "loss: 0.059192  [   30]/  112\n",
            "loss: 0.021996  [   40]/  112\n",
            "loss: 0.029105  [   50]/  112\n",
            "loss: 0.025291  [   60]/  112\n",
            "loss: 0.239264  [   70]/  112\n",
            "loss: 0.210443  [   80]/  112\n",
            "loss: 0.159682  [   90]/  112\n",
            "loss: 0.031974  [  100]/  112\n",
            "loss: 0.009782  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.097712\n",
            "\n",
            "Epoch 75 \n",
            "------------------------\n",
            "loss: 0.143216  [    0]/  112\n",
            "loss: 0.036386  [   10]/  112\n",
            "loss: 0.150336  [   20]/  112\n",
            "loss: 0.056519  [   30]/  112\n",
            "loss: 0.078907  [   40]/  112\n",
            "loss: 0.029661  [   50]/  112\n",
            "loss: 0.066354  [   60]/  112\n",
            "loss: 0.041966  [   70]/  112\n",
            "loss: 0.008659  [   80]/  112\n",
            "loss: 0.364529  [   90]/  112\n",
            "loss: 0.029688  [  100]/  112\n",
            "loss: 0.000601  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.095105\n",
            "\n",
            "Epoch 76 \n",
            "------------------------\n",
            "loss: 0.047070  [    0]/  112\n",
            "loss: 0.030302  [   10]/  112\n",
            "loss: 0.098939  [   20]/  112\n",
            "loss: 0.028310  [   30]/  112\n",
            "loss: 0.106921  [   40]/  112\n",
            "loss: 0.147937  [   50]/  112\n",
            "loss: 0.070683  [   60]/  112\n",
            "loss: 0.185850  [   70]/  112\n",
            "loss: 0.064645  [   80]/  112\n",
            "loss: 0.142251  [   90]/  112\n",
            "loss: 0.078344  [  100]/  112\n",
            "loss: 0.001029  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.092161\n",
            "\n",
            "Epoch 77 \n",
            "------------------------\n",
            "loss: 0.030258  [    0]/  112\n",
            "loss: 0.277774  [   10]/  112\n",
            "loss: 0.107493  [   20]/  112\n",
            "loss: 0.038795  [   30]/  112\n",
            "loss: 0.154863  [   40]/  112\n",
            "loss: 0.059585  [   50]/  112\n",
            "loss: 0.042225  [   60]/  112\n",
            "loss: 0.090959  [   70]/  112\n",
            "loss: 0.034190  [   80]/  112\n",
            "loss: 0.078145  [   90]/  112\n",
            "loss: 0.059351  [  100]/  112\n",
            "loss: 0.070129  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.096319\n",
            "\n",
            "Epoch 78 \n",
            "------------------------\n",
            "loss: 0.144142  [    0]/  112\n",
            "loss: 0.242875  [   10]/  112\n",
            "loss: 0.122390  [   20]/  112\n",
            "loss: 0.038364  [   30]/  112\n",
            "loss: 0.122367  [   40]/  112\n",
            "loss: 0.091925  [   50]/  112\n",
            "loss: 0.017136  [   60]/  112\n",
            "loss: 0.020873  [   70]/  112\n",
            "loss: 0.084638  [   80]/  112\n",
            "loss: 0.068757  [   90]/  112\n",
            "loss: 0.030620  [  100]/  112\n",
            "loss: 0.022240  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.088407\n",
            "\n",
            "Epoch 79 \n",
            "------------------------\n",
            "loss: 0.044555  [    0]/  112\n",
            "loss: 0.075262  [   10]/  112\n",
            "loss: 0.065663  [   20]/  112\n",
            "loss: 0.082977  [   30]/  112\n",
            "loss: 0.029020  [   40]/  112\n",
            "loss: 0.010098  [   50]/  112\n",
            "loss: 0.296007  [   60]/  112\n",
            "loss: 0.111494  [   70]/  112\n",
            "loss: 0.075212  [   80]/  112\n",
            "loss: 0.141236  [   90]/  112\n",
            "loss: 0.039734  [  100]/  112\n",
            "loss: 0.042553  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.092356\n",
            "\n",
            "Epoch 80 \n",
            "------------------------\n",
            "loss: 0.031488  [    0]/  112\n",
            "loss: 0.139903  [   10]/  112\n",
            "loss: 0.024313  [   20]/  112\n",
            "loss: 0.207695  [   30]/  112\n",
            "loss: 0.229294  [   40]/  112\n",
            "loss: 0.119340  [   50]/  112\n",
            "loss: 0.053195  [   60]/  112\n",
            "loss: 0.030225  [   70]/  112\n",
            "loss: 0.101230  [   80]/  112\n",
            "loss: 0.013873  [   90]/  112\n",
            "loss: 0.020962  [  100]/  112\n",
            "loss: 0.102810  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.089015\n",
            "\n",
            "Epoch 81 \n",
            "------------------------\n",
            "loss: 0.050174  [    0]/  112\n",
            "loss: 0.149744  [   10]/  112\n",
            "loss: 0.104358  [   20]/  112\n",
            "loss: 0.026354  [   30]/  112\n",
            "loss: 0.206429  [   40]/  112\n",
            "loss: 0.058814  [   50]/  112\n",
            "loss: 0.029311  [   60]/  112\n",
            "loss: 0.162179  [   70]/  112\n",
            "loss: 0.081577  [   80]/  112\n",
            "loss: 0.063744  [   90]/  112\n",
            "loss: 0.033196  [  100]/  112\n",
            "loss: 0.035133  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.086329\n",
            "\n",
            "Epoch 82 \n",
            "------------------------\n",
            "loss: 0.043005  [    0]/  112\n",
            "loss: 0.025211  [   10]/  112\n",
            "loss: 0.014851  [   20]/  112\n",
            "loss: 0.040962  [   30]/  112\n",
            "loss: 0.323061  [   40]/  112\n",
            "loss: 0.033811  [   50]/  112\n",
            "loss: 0.066560  [   60]/  112\n",
            "loss: 0.192943  [   70]/  112\n",
            "loss: 0.154909  [   80]/  112\n",
            "loss: 0.026477  [   90]/  112\n",
            "loss: 0.046542  [  100]/  112\n",
            "loss: 0.023170  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.087011\n",
            "\n",
            "Epoch 83 \n",
            "------------------------\n",
            "loss: 0.092515  [    0]/  112\n",
            "loss: 0.023427  [   10]/  112\n",
            "loss: 0.024708  [   20]/  112\n",
            "loss: 0.089521  [   30]/  112\n",
            "loss: 0.026447  [   40]/  112\n",
            "loss: 0.008799  [   50]/  112\n",
            "loss: 0.033319  [   60]/  112\n",
            "loss: 0.021275  [   70]/  112\n",
            "loss: 0.270699  [   80]/  112\n",
            "loss: 0.126808  [   90]/  112\n",
            "loss: 0.204576  [  100]/  112\n",
            "loss: 0.083168  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.084057\n",
            "\n",
            "Epoch 84 \n",
            "------------------------\n",
            "loss: 0.016107  [    0]/  112\n",
            "loss: 0.045768  [   10]/  112\n",
            "loss: 0.146314  [   20]/  112\n",
            "loss: 0.240923  [   30]/  112\n",
            "loss: 0.219321  [   40]/  112\n",
            "loss: 0.035972  [   50]/  112\n",
            "loss: 0.063082  [   60]/  112\n",
            "loss: 0.044051  [   70]/  112\n",
            "loss: 0.053001  [   80]/  112\n",
            "loss: 0.089701  [   90]/  112\n",
            "loss: 0.034600  [  100]/  112\n",
            "loss: 0.004892  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.088892\n",
            "\n",
            "Epoch 85 \n",
            "------------------------\n",
            "loss: 0.038832  [    0]/  112\n",
            "loss: 0.036435  [   10]/  112\n",
            "loss: 0.051885  [   20]/  112\n",
            "loss: 0.073934  [   30]/  112\n",
            "loss: 0.084144  [   40]/  112\n",
            "loss: 0.191841  [   50]/  112\n",
            "loss: 0.055757  [   60]/  112\n",
            "loss: 0.237525  [   70]/  112\n",
            "loss: 0.039492  [   80]/  112\n",
            "loss: 0.110248  [   90]/  112\n",
            "loss: 0.043876  [  100]/  112\n",
            "loss: 0.005536  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.085755\n",
            "\n",
            "Epoch 86 \n",
            "------------------------\n",
            "loss: 0.065124  [    0]/  112\n",
            "loss: 0.211117  [   10]/  112\n",
            "loss: 0.078557  [   20]/  112\n",
            "loss: 0.021833  [   30]/  112\n",
            "loss: 0.019861  [   40]/  112\n",
            "loss: 0.061551  [   50]/  112\n",
            "loss: 0.227468  [   60]/  112\n",
            "loss: 0.037461  [   70]/  112\n",
            "loss: 0.112303  [   80]/  112\n",
            "loss: 0.006694  [   90]/  112\n",
            "loss: 0.086741  [  100]/  112\n",
            "loss: 0.001081  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.084957\n",
            "\n",
            "Epoch 87 \n",
            "------------------------\n",
            "loss: 0.131417  [    0]/  112\n",
            "loss: 0.091517  [   10]/  112\n",
            "loss: 0.053371  [   20]/  112\n",
            "loss: 0.021971  [   30]/  112\n",
            "loss: 0.239898  [   40]/  112\n",
            "loss: 0.013250  [   50]/  112\n",
            "loss: 0.099292  [   60]/  112\n",
            "loss: 0.045517  [   70]/  112\n",
            "loss: 0.058610  [   80]/  112\n",
            "loss: 0.100551  [   90]/  112\n",
            "loss: 0.093943  [  100]/  112\n",
            "loss: 0.096788  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.082117\n",
            "\n",
            "Epoch 88 \n",
            "------------------------\n",
            "loss: 0.228171  [    0]/  112\n",
            "loss: 0.100972  [   10]/  112\n",
            "loss: 0.055801  [   20]/  112\n",
            "loss: 0.228582  [   30]/  112\n",
            "loss: 0.017786  [   40]/  112\n",
            "loss: 0.024958  [   50]/  112\n",
            "loss: 0.120839  [   60]/  112\n",
            "loss: 0.020062  [   70]/  112\n",
            "loss: 0.090430  [   80]/  112\n",
            "loss: 0.037031  [   90]/  112\n",
            "loss: 0.015808  [  100]/  112\n",
            "loss: 0.034315  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.083078\n",
            "\n",
            "Epoch 89 \n",
            "------------------------\n",
            "loss: 0.025801  [    0]/  112\n",
            "loss: 0.058801  [   10]/  112\n",
            "loss: 0.092370  [   20]/  112\n",
            "loss: 0.015263  [   30]/  112\n",
            "loss: 0.118479  [   40]/  112\n",
            "loss: 0.171282  [   50]/  112\n",
            "loss: 0.023703  [   60]/  112\n",
            "loss: 0.122403  [   70]/  112\n",
            "loss: 0.045297  [   80]/  112\n",
            "loss: 0.210147  [   90]/  112\n",
            "loss: 0.046333  [  100]/  112\n",
            "loss: 0.001726  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.080248\n",
            "\n",
            "Epoch 90 \n",
            "------------------------\n",
            "loss: 0.219555  [    0]/  112\n",
            "loss: 0.030837  [   10]/  112\n",
            "loss: 0.050131  [   20]/  112\n",
            "loss: 0.087377  [   30]/  112\n",
            "loss: 0.025106  [   40]/  112\n",
            "loss: 0.157423  [   50]/  112\n",
            "loss: 0.036044  [   60]/  112\n",
            "loss: 0.018202  [   70]/  112\n",
            "loss: 0.130497  [   80]/  112\n",
            "loss: 0.066757  [   90]/  112\n",
            "loss: 0.120437  [  100]/  112\n",
            "loss: 0.002013  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.079857\n",
            "\n",
            "Epoch 91 \n",
            "------------------------\n",
            "loss: 0.101849  [    0]/  112\n",
            "loss: 0.214842  [   10]/  112\n",
            "loss: 0.044189  [   20]/  112\n",
            "loss: 0.022509  [   30]/  112\n",
            "loss: 0.065641  [   40]/  112\n",
            "loss: 0.020770  [   50]/  112\n",
            "loss: 0.086418  [   60]/  112\n",
            "loss: 0.077131  [   70]/  112\n",
            "loss: 0.064406  [   80]/  112\n",
            "loss: 0.061226  [   90]/  112\n",
            "loss: 0.158876  [  100]/  112\n",
            "loss: 0.035464  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.083140\n",
            "\n",
            "Epoch 92 \n",
            "------------------------\n",
            "loss: 0.023918  [    0]/  112\n",
            "loss: 0.079609  [   10]/  112\n",
            "loss: 0.037424  [   20]/  112\n",
            "loss: 0.108518  [   30]/  112\n",
            "loss: 0.035354  [   40]/  112\n",
            "loss: 0.052451  [   50]/  112\n",
            "loss: 0.062712  [   60]/  112\n",
            "loss: 0.116409  [   70]/  112\n",
            "loss: 0.042479  [   80]/  112\n",
            "loss: 0.083054  [   90]/  112\n",
            "loss: 0.288777  [  100]/  112\n",
            "loss: 0.007645  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.078415\n",
            "\n",
            "Epoch 93 \n",
            "------------------------\n",
            "loss: 0.247739  [    0]/  112\n",
            "loss: 0.084433  [   10]/  112\n",
            "loss: 0.088386  [   20]/  112\n",
            "loss: 0.014192  [   30]/  112\n",
            "loss: 0.034001  [   40]/  112\n",
            "loss: 0.050517  [   50]/  112\n",
            "loss: 0.033114  [   60]/  112\n",
            "loss: 0.080464  [   70]/  112\n",
            "loss: 0.135031  [   80]/  112\n",
            "loss: 0.065285  [   90]/  112\n",
            "loss: 0.059027  [  100]/  112\n",
            "loss: 0.067347  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.082684\n",
            "\n",
            "Epoch 94 \n",
            "------------------------\n",
            "loss: 0.072418  [    0]/  112\n",
            "loss: 0.085614  [   10]/  112\n",
            "loss: 0.092452  [   20]/  112\n",
            "loss: 0.110823  [   30]/  112\n",
            "loss: 0.200310  [   40]/  112\n",
            "loss: 0.088961  [   50]/  112\n",
            "loss: 0.034180  [   60]/  112\n",
            "loss: 0.029999  [   70]/  112\n",
            "loss: 0.071272  [   80]/  112\n",
            "loss: 0.031382  [   90]/  112\n",
            "loss: 0.047398  [  100]/  112\n",
            "loss: 0.151418  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.078107\n",
            "\n",
            "Epoch 95 \n",
            "------------------------\n",
            "loss: 0.022306  [    0]/  112\n",
            "loss: 0.029492  [   10]/  112\n",
            "loss: 0.052440  [   20]/  112\n",
            "loss: 0.045834  [   30]/  112\n",
            "loss: 0.140065  [   40]/  112\n",
            "loss: 0.122823  [   50]/  112\n",
            "loss: 0.032914  [   60]/  112\n",
            "loss: 0.152146  [   70]/  112\n",
            "loss: 0.247128  [   80]/  112\n",
            "loss: 0.078384  [   90]/  112\n",
            "loss: 0.050126  [  100]/  112\n",
            "loss: 0.019610  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.078356\n",
            "\n",
            "Epoch 96 \n",
            "------------------------\n",
            "loss: 0.138147  [    0]/  112\n",
            "loss: 0.044314  [   10]/  112\n",
            "loss: 0.162440  [   20]/  112\n",
            "loss: 0.103358  [   30]/  112\n",
            "loss: 0.186311  [   40]/  112\n",
            "loss: 0.007248  [   50]/  112\n",
            "loss: 0.065959  [   60]/  112\n",
            "loss: 0.030664  [   70]/  112\n",
            "loss: 0.081500  [   80]/  112\n",
            "loss: 0.069498  [   90]/  112\n",
            "loss: 0.009722  [  100]/  112\n",
            "loss: 0.215391  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.082094\n",
            "\n",
            "Epoch 97 \n",
            "------------------------\n",
            "loss: 0.088535  [    0]/  112\n",
            "loss: 0.057706  [   10]/  112\n",
            "loss: 0.143600  [   20]/  112\n",
            "loss: 0.047871  [   30]/  112\n",
            "loss: 0.032404  [   40]/  112\n",
            "loss: 0.265204  [   50]/  112\n",
            "loss: 0.191869  [   60]/  112\n",
            "loss: 0.014711  [   70]/  112\n",
            "loss: 0.063773  [   80]/  112\n",
            "loss: 0.030243  [   90]/  112\n",
            "loss: 0.012546  [  100]/  112\n",
            "loss: 0.108944  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.080346\n",
            "\n",
            "Epoch 98 \n",
            "------------------------\n",
            "loss: 0.010836  [    0]/  112\n",
            "loss: 0.010397  [   10]/  112\n",
            "loss: 0.013292  [   20]/  112\n",
            "loss: 0.055717  [   30]/  112\n",
            "loss: 0.015657  [   40]/  112\n",
            "loss: 0.306524  [   50]/  112\n",
            "loss: 0.212460  [   60]/  112\n",
            "loss: 0.102108  [   70]/  112\n",
            "loss: 0.030674  [   80]/  112\n",
            "loss: 0.018255  [   90]/  112\n",
            "loss: 0.107771  [  100]/  112\n",
            "loss: 0.003078  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.083097\n",
            "\n",
            "Epoch 99 \n",
            "------------------------\n",
            "loss: 0.055787  [    0]/  112\n",
            "loss: 0.100400  [   10]/  112\n",
            "loss: 0.049353  [   20]/  112\n",
            "loss: 0.078046  [   30]/  112\n",
            "loss: 0.288222  [   40]/  112\n",
            "loss: 0.012179  [   50]/  112\n",
            "loss: 0.031580  [   60]/  112\n",
            "loss: 0.013111  [   70]/  112\n",
            "loss: 0.115345  [   80]/  112\n",
            "loss: 0.092267  [   90]/  112\n",
            "loss: 0.072272  [  100]/  112\n",
            "loss: 0.011937  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.074185\n",
            "\n",
            "Epoch 100 \n",
            "------------------------\n",
            "loss: 0.061630  [    0]/  112\n",
            "loss: 0.103946  [   10]/  112\n",
            "loss: 0.031638  [   20]/  112\n",
            "loss: 0.257002  [   30]/  112\n",
            "loss: 0.050917  [   40]/  112\n",
            "loss: 0.011284  [   50]/  112\n",
            "loss: 0.086102  [   60]/  112\n",
            "loss: 0.115594  [   70]/  112\n",
            "loss: 0.067286  [   80]/  112\n",
            "loss: 0.057945  [   90]/  112\n",
            "loss: 0.013621  [  100]/  112\n",
            "loss: 0.047855  [   22]/  112\n",
            "Test Error: \n",
            " Accuracy: 100.0%, Avg loss: 0.073012\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}